











---
## âš™ï¸ Regras de ConcessÃ£o (LÃ³gica de NegÃ³cio)
O motor de decisÃ£o aplica lÃ³gicas de negÃ³cio diretamente em Dataframes Spark:
 **1. CÃ¡lculo de Capacidade:** O limite da parcela nÃ£o pode exceder 30% da renda mensal.

 **2. Hard Rules (ReprovaÃ§Ã£o AutomÃ¡tica):**

    â€¢ Cliente com restriÃ§Ã£o ativa no Bureau Externo (SPC/Serasa).

    â€¢ Endividamento total de mercado superior a 10x a renda mensal.

 **Exemplo de CÃ³digo Modularizado (src/transformations.py)**

def aplicar_regras_credito(df):
    return df.withColumn(
        "status_analise",
        when(
            (col("restricao_spc") == "S") | 
            (col("divida_total_mercado") > (col("renda_mensal") * 10)), 
            lit("REPROVADO_RISCO")
        ).otherwise(lit("APROVADO"))
    )

## ðŸ“‚ Estrutura do Projeto Profissional

coop-credit-engine/
â”œâ”€â”€ .github/workflows/   # Pipeline de CI/CD (GitHub Actions)
â”œâ”€â”€ dags/                # OrquestraÃ§Ã£o do Airflow
â”œâ”€â”€ docs/                # DocumentaÃ§Ã£o e ADRs
â”œâ”€â”€ src/                 # CÃ³digo Fonte (LÃ³gica Pura Spark)
â”œâ”€â”€ tests/               # Testes UnitÃ¡rios Automatizados
â”œâ”€â”€ docker-compose.yaml  # Infraestrutura como CÃ³digo
â”œâ”€â”€ Makefile             # AutomaÃ§Ã£o de comandos
â””â”€â”€ README.md            # DocumentaÃ§Ã£o Geral

## ðŸ“¸ EvidÃªncias de ExecuÃ§Ã£o

### 1. Pipeline de Dados (Airflow)
Fluxo completo de ingestÃ£o, processamento Spark e carga no DW executado com sucesso.
![Fluxo Airflow](https://github.com/ricardoribs/Coop-Credit-Engine/blob/main/airflow.PNG)

### 2. Resultado da AnÃ¡lise (Data Warehouse)
Consulta final demonstrando a aplicaÃ§Ã£o das regras. Note que clientes com dÃ­vidas altas ou restriÃ§Ãµes foram automaticamente classificados como `REPROVADO_RISCO`.
![Tabela SQL](https://github.com/ricardoribs/Coop-Credit-Engine/blob/main/resultado.PNG)        


## ðŸš€ Como Executar

**1. PrÃ©-requisitos**
 â€¢ Docker & Docker Compose

**2. Rodar o Pipeline Completo**
 docker-compose up --build

Acesse:
ðŸ‘‰ Airflow: http://localhost:8080

Login/Senha: airflow / airflow

**3. Rodar Testes sem Docker**
pip install -r requirements.txt
pytest tests/ -v

