# ðŸ¦ Coop-Credit Engine: Pipeline de Risco de CrÃ©dito com Spark

![CI Status](https://github.com/ricardoribs/coop-credit-engine/actions/workflows/ci.yml/badge.svg)
![Spark](https://img.shields.io/badge/Big%20Data-PySpark-orange?style=for-the-badge&logo=apachespark)
![Airflow](https://img.shields.io/badge/Orchestration-Apache%20Airflow-blue?style=for-the-badge&logo=apacheairflow)
![Tests](https://img.shields.io/badge/Tests-Pytest-green?style=for-the-badge&logo=pytest)

> **Contexto:** Projeto de Engenharia de Dados desenvolvido para automatizar a anÃ¡lise de concessÃ£o e risco de crÃ©dito em uma Cooperativa, utilizando arquitetura distribuÃ­da e boas prÃ¡ticas de Engenharia de Software (CI/CD, Testes UnitÃ¡rios e ModularizaÃ§Ã£o).

---

## ðŸ“Œ 1. Problema de NegÃ³cio

Uma Cooperativa processa milhares de solicitaÃ§Ãµes de emprÃ©stimo por dia. O processo manual atrasa aprovaÃ§Ãµes, aumenta erros e nÃ£o escala.

ðŸŽ¯ **Objetivo:** Criar um *Decision Engine* capaz de aprovar ou reprovar crÃ©dito em segundos, cruzando:
* Renda declarada
* DÃ­vidas de mercado
* RestriÃ§Ãµes de bureaus externos

Tudo num pipeline confiÃ¡vel e totalmente automatizado.

---

## âš™ï¸ 2. Arquitetura do Sistema

Este projeto segue boas prÃ¡ticas de Engenharia de Software aplicadas a dados:
* **CÃ³digo Modular:** FunÃ§Ãµes puras, testÃ¡veis e desacopladas do Airflow (`src/`).
* **Qualidade:** Testes unitÃ¡rios para validar lÃ³gica de crÃ©dito antes do deploy.
* **CI/CD:** GitHub Actions para validaÃ§Ã£o contÃ­nua.
* **Infraestrutura:** Containers reproduzÃ­veis (Spark + Airflow).

### ðŸ”§ Stack TecnolÃ³gica

* **Processamento:** Apache Spark (PySpark) â€“ *compatÃ­vel com Databricks*
* **OrquestraÃ§Ã£o:** Apache Airflow 2.9
* **Infraestrutura:** Docker/JDK integrado
* **Qualidade:** Pytest + GitHub Actions

---

## ðŸ—ºï¸ 3. Diagrama da Arquitetura


```mermaid
graph LR
    subgraph Fontes
    A[Cadastro Cooperado] 
    B[Bureau Externo]
    end

    subgraph "Core (PySpark)"
    A -->|IngestÃ£o| C{Cluster Spark}
    B -->|IngestÃ£o| C
    C -->|TransformaÃ§Ã£o| D[CÃ¡lculo: Renda Comprometida]
    D -->|Motor de Regras| E[ClassificaÃ§Ã£o de Risco]
    end

    subgraph Entrega
    E -->|PersistÃªncia| F[(Data Warehouse PostgreSQL)]
    end

    style C fill:#ff9900,stroke:#333,stroke-width:2px
    style D fill:#fafafa,stroke:#333
    style E fill:#fafafa,stroke:#333



## âš™ï¸ Regras de ConcessÃ£o (LÃ³gica de NegÃ³cio)
O motor de decisÃ£o aplica lÃ³gicas de negÃ³cio diretamente em Dataframes Spark:
 **1. CÃ¡lculo de Capacidade:** O limite da parcela nÃ£o pode exceder 30% da renda mensal.

 **2. Hard Rules (ReprovaÃ§Ã£o AutomÃ¡tica):**

    â€¢ Cliente com restriÃ§Ã£o ativa no Bureau Externo (SPC/Serasa).

    â€¢ Endividamento total de mercado superior a 10x a renda mensal.

 **Exemplo de CÃ³digo Modularizado (src/transformations.py)**

def aplicar_regras_credito(df):
    return df.withColumn(
        "status_analise",
        when(
            (col("restricao_spc") == "S") | 
            (col("divida_total_mercado") > (col("renda_mensal") * 10)), 
            lit("REPROVADO_RISCO")
        ).otherwise(lit("APROVADO"))
    )

## ðŸ“‚ Estrutura do Projeto Profissional

coop-credit-engine/
â”œâ”€â”€ .github/workflows/   # Pipeline de CI/CD (GitHub Actions)
â”œâ”€â”€ dags/                # OrquestraÃ§Ã£o do Airflow
â”œâ”€â”€ docs/                # DocumentaÃ§Ã£o e ADRs
â”œâ”€â”€ src/                 # CÃ³digo Fonte (LÃ³gica Pura Spark)
â”œâ”€â”€ tests/               # Testes UnitÃ¡rios Automatizados
â”œâ”€â”€ docker-compose.yaml  # Infraestrutura como CÃ³digo
â”œâ”€â”€ Makefile             # AutomaÃ§Ã£o de comandos
â””â”€â”€ README.md            # DocumentaÃ§Ã£o Geral

## ðŸ“¸ EvidÃªncias de ExecuÃ§Ã£o

### 1. Pipeline de Dados (Airflow)
Fluxo completo de ingestÃ£o, processamento Spark e carga no DW executado com sucesso.
![Fluxo Airflow](https://github.com/ricardoribs/Coop-Credit-Engine/blob/main/airflow.PNG)

### 2. Resultado da AnÃ¡lise (Data Warehouse)
Consulta final demonstrando a aplicaÃ§Ã£o das regras. Note que clientes com dÃ­vidas altas ou restriÃ§Ãµes foram automaticamente classificados como `REPROVADO_RISCO`.
![Tabela SQL](https://github.com/ricardoribs/Coop-Credit-Engine/blob/main/resultado.PNG)        


## ðŸš€ Como Executar

**1. PrÃ©-requisitos**
 â€¢ Docker & Docker Compose

**2. Rodar o Pipeline Completo**
 docker-compose up --build

Acesse:
ðŸ‘‰ Airflow: http://localhost:8080

Login/Senha: airflow / airflow

**3. Rodar Testes sem Docker**
pip install -r requirements.txt
pytest tests/ -v

